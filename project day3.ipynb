{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  In-class Labexercise\n",
    "## Case-study 1 ( KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-da4c5cafbcd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure_factory\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mff\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from  sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_1samp,wilcoxon,shapiro,ttest_ind,levene,bartlett,mannwhitneyu\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "%matplotlib inline\n",
    "from statsmodels.stats.power import ttest_power\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "boston=load_boston()\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.api as smi\n",
    "import statsmodels.tsa.api as smt\n",
    "from scipy import stats\n",
    "import statsmodels.stats.api as sms\n",
    "import scipy.stats as stats\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "import pylab\n",
    "from sklearn.feature_selection import RFE\n",
    "from statsmodels.compat import lzip\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "import plotly.express as px \n",
    "import plotly.graph_objects as go \n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Read the dataset(PlayTennis.csv):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/bhavna singh/Downloads/PlayTennis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Use the  LabelEncoder(Concerting categarical to Numarical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play Tennis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outlook  Temperature  Humidity  Wind  Play Tennis\n",
       "0         2            1         0     1            0\n",
       "1         2            1         0     0            0\n",
       "2         0            1         0     1            1\n",
       "3         1            2         0     1            1\n",
       "4         1            0         1     1            1\n",
       "5         1            0         1     0            0\n",
       "6         0            0         1     0            1\n",
       "7         2            2         0     1            0\n",
       "8         2            0         1     1            1\n",
       "9         1            2         1     1            1\n",
       "10        2            2         1     0            1\n",
       "11        0            2         0     0            1\n",
       "12        0            1         1     1            1\n",
       "13        1            2         0     0            0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "number=preprocessing.LabelEncoder()\n",
    "df['Outlook']=number.fit_transform(df['Outlook'])\n",
    "df['Temperature']=number.fit_transform(df['Temperature'])\n",
    "df['Humidity']=number.fit_transform(df['Humidity'])\n",
    "df['Wind']=number.fit_transform(df['Wind'])\n",
    "df['Play Tennis']=number.fit_transform(df['Play Tennis'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Extract the independent variable X and dependent variable Y?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Play Tennis',axis=1)\n",
    "Y=df['Play Tennis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Visualize the data:(countplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ff2c487b00>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Play Tennis',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Split the data into train and test set:(70/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Train a knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "#x,y=df.loc[:,df.columns!='class'],df.loc[:,'class']\n",
    "knn.fit(x_train,y_train)\n",
    "prediction=knn.predict(x_test)\n",
    "knn.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Predict the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=knn.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Evaluation the model:(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.60      1.00      0.75         3\n",
      "\n",
      "   micro avg       0.60      0.60      0.60         5\n",
      "   macro avg       0.30      0.50      0.37         5\n",
      "weighted avg       0.36      0.60      0.45         5\n",
      "\n",
      "accuracy_score: 0.6\n"
     ]
    }
   ],
   "source": [
    "print('classification_report:',classification_report(y_test,y_pred))\n",
    "print('accuracy_score:',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case-study 2  (NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importing the dataset(pima-indians-diabetes.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv('C:/Users/bhavna singh/Desktop/data science/datasets/diabetes.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Find out the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>235</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>196</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>119</td>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>143</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>146</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>115</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>15</td>\n",
       "      <td>140</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>160</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.293</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>150</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>94</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>58</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>9</td>\n",
       "      <td>140</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>13</td>\n",
       "      <td>153</td>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "      <td>140</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1.174</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>105</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>94</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>74</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6</td>\n",
       "      <td>162</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>62</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>8</td>\n",
       "      <td>154</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.443</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>7</td>\n",
       "      <td>137</td>\n",
       "      <td>90</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "5              5      116             74              0        0  25.6   \n",
       "6              3       78             50             32       88  31.0   \n",
       "7             10      115              0              0        0  35.3   \n",
       "8              2      197             70             45      543  30.5   \n",
       "9              8      125             96              0        0   0.0   \n",
       "10             4      110             92              0        0  37.6   \n",
       "11            10      168             74              0        0  38.0   \n",
       "12            10      139             80              0        0  27.1   \n",
       "13             1      189             60             23      846  30.1   \n",
       "14             5      166             72             19      175  25.8   \n",
       "15             7      100              0              0        0  30.0   \n",
       "16             0      118             84             47      230  45.8   \n",
       "17             7      107             74              0        0  29.6   \n",
       "18             1      103             30             38       83  43.3   \n",
       "19             1      115             70             30       96  34.6   \n",
       "20             3      126             88             41      235  39.3   \n",
       "21             8       99             84              0        0  35.4   \n",
       "22             7      196             90              0        0  39.8   \n",
       "23             9      119             80             35        0  29.0   \n",
       "24            11      143             94             33      146  36.6   \n",
       "25            10      125             70             26      115  31.1   \n",
       "26             7      147             76              0        0  39.4   \n",
       "27             1       97             66             15      140  23.2   \n",
       "28            13      145             82             19      110  22.2   \n",
       "29             5      117             92              0        0  34.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "738            2       99             60             17      160  36.6   \n",
       "739            1      102             74              0        0  39.5   \n",
       "740           11      120             80             37      150  42.3   \n",
       "741            3      102             44             20       94  30.8   \n",
       "742            1      109             58             18      116  28.5   \n",
       "743            9      140             94              0        0  32.7   \n",
       "744           13      153             88             37      140  40.6   \n",
       "745           12      100             84             33      105  30.0   \n",
       "746            1      147             94             41        0  49.3   \n",
       "747            1       81             74             41       57  46.3   \n",
       "748            3      187             70             22      200  36.4   \n",
       "749            6      162             62              0        0  24.3   \n",
       "750            4      136             70              0        0  31.2   \n",
       "751            1      121             78             39       74  39.0   \n",
       "752            3      108             62             24        0  26.0   \n",
       "753            0      181             88             44      510  43.3   \n",
       "754            8      154             78             32        0  32.4   \n",
       "755            1      128             88             39      110  36.5   \n",
       "756            7      137             90             41        0  32.0   \n",
       "757            0      123             72              0        0  36.3   \n",
       "758            1      106             76              0        0  37.5   \n",
       "759            6      190             92              0        0  35.5   \n",
       "760            2       88             58             26       16  28.4   \n",
       "761            9      170             74             31        0  44.0   \n",
       "762            9       89             62              0        0  22.5   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "5                       0.201   30        0  \n",
       "6                       0.248   26        1  \n",
       "7                       0.134   29        0  \n",
       "8                       0.158   53        1  \n",
       "9                       0.232   54        1  \n",
       "10                      0.191   30        0  \n",
       "11                      0.537   34        1  \n",
       "12                      1.441   57        0  \n",
       "13                      0.398   59        1  \n",
       "14                      0.587   51        1  \n",
       "15                      0.484   32        1  \n",
       "16                      0.551   31        1  \n",
       "17                      0.254   31        1  \n",
       "18                      0.183   33        0  \n",
       "19                      0.529   32        1  \n",
       "20                      0.704   27        0  \n",
       "21                      0.388   50        0  \n",
       "22                      0.451   41        1  \n",
       "23                      0.263   29        1  \n",
       "24                      0.254   51        1  \n",
       "25                      0.205   41        1  \n",
       "26                      0.257   43        1  \n",
       "27                      0.487   22        0  \n",
       "28                      0.245   57        0  \n",
       "29                      0.337   38        0  \n",
       "..                        ...  ...      ...  \n",
       "738                     0.453   21        0  \n",
       "739                     0.293   42        1  \n",
       "740                     0.785   48        1  \n",
       "741                     0.400   26        0  \n",
       "742                     0.219   22        0  \n",
       "743                     0.734   45        1  \n",
       "744                     1.174   39        0  \n",
       "745                     0.488   46        0  \n",
       "746                     0.358   27        1  \n",
       "747                     1.096   32        0  \n",
       "748                     0.408   36        1  \n",
       "749                     0.178   50        1  \n",
       "750                     1.182   22        1  \n",
       "751                     0.261   28        0  \n",
       "752                     0.223   25        0  \n",
       "753                     0.222   26        1  \n",
       "754                     0.443   45        1  \n",
       "755                     1.057   37        1  \n",
       "756                     0.391   39        0  \n",
       "757                     0.258   52        1  \n",
       "758                     0.197   26        0  \n",
       "759                     0.278   66        1  \n",
       "760                     0.766   22        0  \n",
       "761                     0.403   43        1  \n",
       "762                     0.142   33        0  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Extract the independent variable X and dependent variable Y?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df1.drop('Outcome',axis=1)\n",
    "y=df1.Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Split the data into train and test set:(70/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Train a GaussianNB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7672253258845437"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=GaussianNB()\n",
    "classifier.fit(x_train,y_train)\n",
    "classifier.score(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Predict the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=classifier.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Evaluation the model:(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79       150\n",
      "           1       0.62      0.58      0.60        81\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       231\n",
      "   macro avg       0.70      0.69      0.70       231\n",
      "weighted avg       0.72      0.73      0.73       231\n",
      "\n",
      "accuracy_score: 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "print('classification_report:',classification_report(y_test,y_pred))\n",
    "print('accuracy_score:',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Conclusion:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to score,the model is perfect. TRAIN IS APPROXIMATELY EQUAL TO TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ff2c4d7978>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this produces a 2x2 numpy array (matrix)\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
    "plt.figure(figsize = (8,5))\n",
    "sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 what is Basic terminology For Confusion matrix?\n",
    "\n",
    "True Positives (TP): \n",
    "\n",
    "True Negatives (TN):\n",
    "\n",
    "False Positives (FP): \n",
    "\n",
    "* Falsely predict positive\n",
    "\n",
    "Type I error\n",
    "\n",
    "False Negatives (FN): \n",
    "\n",
    "\n",
    "* Falsely predict negative\n",
    "\n",
    "Type II error\n",
    "\n",
    "0: negative class\n",
    "\n",
    "1: positive class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 print the first 25 true and predicted responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correctly classified : 22\n",
      "incorrectly classified : 3\n"
     ]
    }
   ],
   "source": [
    "ys = np.array(y_test.values)\n",
    "predict = np.array(y_pred)\n",
    "\n",
    "ys = ys[:25]\n",
    "predict = predict[:25]\n",
    "check = (ys.flatten() == predict)\n",
    "correctly_classified = np.count_nonzero(check)\n",
    "incorrectly_classed = np.count_nonzero(~check)\n",
    "print('correctly classified :',correctly_classified)\n",
    "print('incorrectly classified :',incorrectly_classed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.12 save confusion matrix and slice into four pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true +: 47\n",
      "true -: 121\n",
      "false +: 34\n",
      "flase - 29\n"
     ]
    }
   ],
   "source": [
    "TN=cm[0,0]\n",
    "TP=cm[1,1]\n",
    "FN=cm[1,0]\n",
    "FP=cm[0,1]\n",
    "sensitivity=TP/float(TP+FN)\n",
    "specificity=TN/float(TN+FP)\n",
    "print('true +:',TP)\n",
    "print('true -:',TN)\n",
    "print('false +:',FN)\n",
    "print('flase -',FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.13 Metrics computed from a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Accuracy: Overall, how often is the classifier correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The acuuracy of the model = TP+TN / (TP+TN+FP+FN) =  0.7272727272727273 \n",
      "\n",
      " The Miss-classification = 1-Accuracy =  0.2727272727272727 \n",
      "\n",
      " Sensitivity or True Positive Rate = TP / (TP+FN) =  0.5802469135802469 \n",
      "\n",
      " Specificity or True Negative Rate = TN / (TN+FP) =  0.8066666666666666 \n",
      "\n",
      " Positive Predictive value = TP / (TP+FP) =  0.618421052631579 \n",
      "\n",
      " Negative predictive Value = TN / (TN+FN) =  0.7806451612903226 \n",
      "\n",
      " Positive Likelihood Ratio = Sensitivity / (1-Specificity) =  3.0012771392081734 \n",
      "\n",
      " Negative likelihood Ratio = (1-Sensitivity) / Specificity =  0.5203550658096112\n"
     ]
    }
   ],
   "source": [
    "print('The acuuracy of the model = TP+TN / (TP+TN+FP+FN) = ',(TP+TN)/float(TP+TN+FP+FN),'\\n\\n',\n",
    "\n",
    "'The Miss-classification = 1-Accuracy = ',1-((TP+TN)/float(TP+TN+FP+FN)),'\\n\\n',\n",
    "\n",
    "'Sensitivity or True Positive Rate = TP / (TP+FN) = ',TP/float(TP+FN),'\\n\\n',\n",
    "\n",
    "'Specificity or True Negative Rate = TN / (TN+FP) = ',TN/float(TN+FP),'\\n\\n',\n",
    "\n",
    "'Positive Predictive value = TP / (TP+FP) = ',TP/float(TP+FP),'\\n\\n',\n",
    "\n",
    "'Negative predictive Value = TN / (TN+FN) = ',TN/float(TN+FN),'\\n\\n',\n",
    "\n",
    "'Positive Likelihood Ratio = Sensitivity / (1-Specificity) = ',sensitivity/(1-specificity),'\\n\\n',\n",
    "\n",
    "'Negative likelihood Ratio = (1-Sensitivity) / Specificity = ',(1-sensitivity)/specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above statistics it is clear that the model is highly specific than sensitive. The negative values are predicted more accurately than the positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Error: Overall, how often is the classifier incorrect?\n",
    "\n",
    "Also known as \"Misclassification Rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2727272727272727"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = TP+TN+FP+FN\n",
    "accuracy = (TP + TN)/total\n",
    "accuracy\n",
    "miss = (FP+FN)/total\n",
    "miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity: When the actual value is positive, how often is the prediction correct?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5802469135802469"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_positive = TP+FN\n",
    "sensitivity = TP/actual_positive\n",
    "sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity: When the actual value is negative, how often is the prediction correct?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8066666666666666"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_negative = FP+TN\n",
    "specificity = TN/actual_negative\n",
    "specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Positive Rate: When the actual value is negative, how often is the prediction incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19333333333333336"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr = 1 -specificity\n",
    "fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: When a positive value is predicted, how often is the prediction correct?\n",
    "\n",
    "How \"precise\" is the classifier when predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.618421052631579"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_positive = TP\n",
    "positives_by_model=TP+FP\n",
    "precision = correct_positive/positives_by_model\n",
    "precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.14 Adjusting the classification threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob0</th>\n",
       "      <th>prob1</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.740070</td>\n",
       "      <td>0.259930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.446742</td>\n",
       "      <td>0.553258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.976674</td>\n",
       "      <td>0.023326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.280565</td>\n",
       "      <td>0.719435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.894362</td>\n",
       "      <td>0.105638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.994371</td>\n",
       "      <td>0.005629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.318435</td>\n",
       "      <td>0.681565</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.591140</td>\n",
       "      <td>0.408860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.949882</td>\n",
       "      <td>0.050118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.691736</td>\n",
       "      <td>0.308264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        prob0     prob1  predicted\n",
       "100  0.740070  0.259930          0\n",
       "202  0.446742  0.553258          1\n",
       "164  0.976674  0.023326          0\n",
       "99   0.280565  0.719435          1\n",
       "51   0.894362  0.105638          0\n",
       "56   0.994371  0.005629          0\n",
       "11   0.318435  0.681565          1\n",
       "128  0.591140  0.408860          0\n",
       "20   0.949882  0.050118          0\n",
       "200  0.691736  0.308264          0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_prior = 500/(500+268)\n",
    "one_prior = 268/(500+268)\n",
    "gauss_thershold = GaussianNB(priors=[zero_prior,one_prior])\n",
    "gauss_thershold.fit(x_train,y_train)\n",
    "# predictions \n",
    "probs = gauss_thershold.predict_proba(x_test)\n",
    "prediction = gauss_thershold.predict(x_test)\n",
    "probs_df = pd.DataFrame(probs,columns=['prob0','prob1'])\n",
    "output = pd.DataFrame(prediction,columns=['predicted'])\n",
    "threshold_df = pd.concat([probs_df,output],axis=1)\n",
    "threshold_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print the first 10 predicted responses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob0</th>\n",
       "      <th>prob1</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.912858</td>\n",
       "      <td>0.087142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012719</td>\n",
       "      <td>0.987281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.473926</td>\n",
       "      <td>0.526074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999473</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.947329</td>\n",
       "      <td>0.052671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.172182</td>\n",
       "      <td>0.827818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.998369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.942590</td>\n",
       "      <td>0.057410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.544774</td>\n",
       "      <td>0.455226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.962128</td>\n",
       "      <td>0.037872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prob0     prob1  predicted\n",
       "0  0.912858  0.087142          0\n",
       "1  0.012719  0.987281          1\n",
       "2  0.473926  0.526074          1\n",
       "3  0.999473  0.000527          0\n",
       "4  0.947329  0.052671          0\n",
       "5  0.172182  0.827818          1\n",
       "6  0.001631  0.998369          1\n",
       "7  0.942590  0.057410          0\n",
       "8  0.544774  0.455226          0\n",
       "9  0.962128  0.037872          0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print the first 10 predicted probabilities of class membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob0</th>\n",
       "      <th>prob1</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012719</td>\n",
       "      <td>0.987281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.473926</td>\n",
       "      <td>0.526074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.172182</td>\n",
       "      <td>0.827818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.998369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.318435</td>\n",
       "      <td>0.681565</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.036901</td>\n",
       "      <td>0.963099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.164156</td>\n",
       "      <td>0.835844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.126448</td>\n",
       "      <td>0.873552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.290678</td>\n",
       "      <td>0.709322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.239803</td>\n",
       "      <td>0.760197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prob0     prob1  predicted\n",
       "1   0.012719  0.987281          1\n",
       "2   0.473926  0.526074          1\n",
       "5   0.172182  0.827818          1\n",
       "6   0.001631  0.998369          1\n",
       "11  0.318435  0.681565          1\n",
       "13  0.036901  0.963099          1\n",
       "14  0.164156  0.835844          1\n",
       "15  0.126448  0.873552          1\n",
       "21  0.290678  0.709322          1\n",
       "23  0.239803  0.760197          1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_df[threshold_df['predicted']==1].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print the first 10 predicted probabilities for class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob0</th>\n",
       "      <th>prob1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012719</td>\n",
       "      <td>0.987281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.473926</td>\n",
       "      <td>0.526074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.172182</td>\n",
       "      <td>0.827818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.998369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.318435</td>\n",
       "      <td>0.681565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prob0     prob1\n",
       "1   0.012719  0.987281\n",
       "2   0.473926  0.526074\n",
       "5   0.172182  0.827818\n",
       "6   0.001631  0.998369\n",
       "11  0.318435  0.681565"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_df[threshold_df['predicted']==1][['prob0','prob1']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### store the predicted probabilities for class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs1 = threshold_df['prob1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot histogram of predicted probabilities\n",
    "\n",
    "#### create 8 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'px' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-b1df2a5da620>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreshold_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'prob1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'predicted'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Histogram of predicted probabilities with threshold = 0.5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'px' is not defined"
     ]
    }
   ],
   "source": [
    "fig = px.histogram(threshold_df,x='prob1',color='predicted',title='Histogram of predicted probabilities with threshold = 0.5')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print the first 10 predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob0</th>\n",
       "      <th>prob1</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.912858</td>\n",
       "      <td>0.087142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012719</td>\n",
       "      <td>0.987281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.473926</td>\n",
       "      <td>0.526074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999473</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.947329</td>\n",
       "      <td>0.052671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.172182</td>\n",
       "      <td>0.827818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.998369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.942590</td>\n",
       "      <td>0.057410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.544774</td>\n",
       "      <td>0.455226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.962128</td>\n",
       "      <td>0.037872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prob0     prob1  predicted\n",
       "0  0.912858  0.087142          0\n",
       "1  0.012719  0.987281          1\n",
       "2  0.473926  0.526074          1\n",
       "3  0.999473  0.000527          0\n",
       "4  0.947329  0.052671          0\n",
       "5  0.172182  0.827818          1\n",
       "6  0.001631  0.998369          1\n",
       "7  0.942590  0.057410          0\n",
       "8  0.544774  0.455226          0\n",
       "9  0.962128  0.037872          0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create new confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_,sensitivity,specificity = validate_threshold(threshold_df[['prob1']],y_test)\n",
    "s1= np.array(sensitivity)[::-1] # plotted from 100% threshold to 0 for p(y=1|x)\n",
    "s2 = np.array(specificity)[::-1]\n",
    "fpr = 1-s2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.14 Receiver Operating Characteristic (ROC) Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define a function that accepts a threshold and prints sensitivity and specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_threshold(probs,y_test):\n",
    "    pred = []\n",
    "    sens = []\n",
    "    spec = [] \n",
    "    for thresh_value in range(0,11) : # trying 0 and 1  for start and stop points\n",
    "        predictions =  probs[probs.columns[0]].apply(lambda x:1 if x>(thresh_value/10) else 0)\n",
    "        # confusion matrix for each thresh hold value \n",
    "        cm = confusion_matrix(y_test,predictions)\n",
    "        tp = cm[1,1]\n",
    "        tn = cm[0,0]\n",
    "        fp = cm[0,1]\n",
    "        fn = cm[1,0]\n",
    "        actual_positive = tp+fn\n",
    "        sensitivity = tp/actual_positive\n",
    "        actual_negative = fp+tn\n",
    "        specificity = tn/actual_negative\n",
    "        \n",
    "        pred.append(predictions)\n",
    "        sens.append(sensitivity)\n",
    "        spec.append(specificity)\n",
    "        \n",
    "        \n",
    "    return pred,sens,spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. What is advantages Confusion matrix and ROC/AUC?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curves summarize the trade-off between the true positive rate and false positive rate for a predictive model using different probability thresholds.\n",
    "\n",
    "Precision-Recall curves summarize the trade-off between the true positive rate and the positive predictive value for a predictive model using different probability thresholds.\n",
    "\n",
    "ROC curves are appropriate when the observations are balanced between each class, whereas precision-recall curves are appropriate for imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
